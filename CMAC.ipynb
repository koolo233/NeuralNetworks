{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebellar Model Articulation Controller(CMAC)\n",
    "\n",
    "\n",
    "## 概论\n",
    "小脑模型的初始设想很简单，希望设计一个这样的模型：\n",
    "\n",
    "1. **足够快**\n",
    "2. **拟合**\n",
    "\n",
    "### 足够快\n",
    "对于第一点，传统的神经网络均是使用浮点数进行计算，使用浮点数显然存在两个缺点：其一是占用空间大，其二是运算不够快。但也存在非常明显的优点：计算精度高。\n",
    "\n",
    "若为了在不太降低精度的条件下尽可能提高模型运算效率，显然有两个角度：其一是改进模型，其二是改变数值存储方式。\n",
    "\n",
    "量化技术就是这样一类通过改变数值存储方式提高模型运算效率的方式。对于现代神经网络，训练通常采用32位浮点数，推理时则可以选用16位浮点数以提高精度，而当部署到边缘设备上时则可以进一步采用**int8量化技术**。\n",
    "\n",
    "对于CMAC，同样的，为了提升运算效率，初始数据输入时会进行量化。此外，为了进一步提升效率，CMAC还引入了**哈希散列**，通过查表的方式将相近的输入映射到相似的地址上。\n",
    "\n",
    "哈希散列同时也引入了不确定的因素。哈希散列是一种压缩映射，其很有可能将不同的输入映射到同一个地址，即导致了**碰撞**。从另一个角度讲，这也引入了非线性变换，即在原空间可能相隔非常远的两个输入，在映射后可能十分相近甚至发生**碰撞**。\n",
    "\n",
    "\n",
    "### 拟合\n",
    "为了实现拟合，CMAC在查表后建立了一个自适应线性层，实现地址到输出的线性估计\n",
    "由于采用了哈希，实际上建立了输入与地址的映射表。在不考虑碰撞的情况下，一个特定的输入会激活特定的地址，而特定的地址会激活特定的自适应线性层的输入单元，这些单元则会连接到输出。\n",
    "\n",
    "不同于传统的神经网络，进行推理时同层所有的神经元均会参与运算，CMAC中仅有被激活的输入单元才会参与运算，这显然也加速了CMAC的运算速度。\n",
    "\n",
    "\n",
    "## 符号定义\n",
    "\n",
    "### 空间\n",
    "|符号|含义|\n",
    "|:-:|:-:|\n",
    "|$S$|输入空间|\n",
    "|$M$|扩充地址空间|\n",
    "|$MC$|扩充地址空间长度|\n",
    "|$A_c$|虚拟存储空间|\n",
    "|$A_p$|实际存储空间|\n",
    "|$F$|输出空间|\n",
    "\n",
    "### 数据\n",
    "|符号|含义|\n",
    "|:-:|:-:|\n",
    "|$\\bm{s}$|输入向量|\n",
    "|$\\bm{m}$|扩充后矩阵|\n",
    "|$\\bm{a}$|虚拟存储空间向量|\n",
    "|$\\bm{d}$|实际存储空间向量|\n",
    "|$\\bm{\\hat{y}}$|预测输出|\n",
    "|$\\bm{y}$|真实输出|\n",
    "\n",
    "### 参数\n",
    "|符号|含义|\n",
    "|:-:|:-:|\n",
    "|s|输入空间维度|\n",
    "|q|量化级|\n",
    "|c|扩充地址维度|\n",
    "|$\\bm{W}$|输出权值矩阵|\n",
    "\n",
    "\n",
    "## 正向运算\n",
    "\n",
    "CMAC的整体流程如下：\n",
    "\n",
    "* 输入空间$S$离散化\n",
    "* 输入空间$S$ $\\rightarrow$ 扩充地址空间$M$\n",
    "* 扩充地址空间$M$ $\\rightarrow$ 虚拟存储空间$A_c$\n",
    "* 虚拟存储空间$A_c$ $\\rightarrow$ 实际存储空间$A_p$\n",
    "* 实际存储空间$A_p$ $\\rightarrow$ 输出空间$F$\n",
    "\n",
    "第零步为离散化。一方面是加速运算，另一方面也是配合后续的Hash\n",
    "\n",
    "第一步是在进行升维\n",
    "\n",
    "第二步是将第一步中升维到高维的多个分量组合为一个向量\n",
    "\n",
    "第三步为Hash\n",
    "\n",
    "第四步为自适应线性拟合\n",
    "\n",
    "### 离散化\n",
    "\n",
    "输入为$\\bm{s}=[s_1, s_2, \\cdots, s_s]$\n",
    "\n",
    "设定第n个维度的取值范围为$[n_{min}, n_{max}]$，量化级为q_n\n",
    "\n",
    "则第n个维度的离散值为\n",
    "$$\n",
    "\\begin{equation}\n",
    "    s_n = \\lceil\\frac{(s_n-n_{min})}{(n_{max}-n_{min})}*q_n\\rceil\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### 输入空间到扩充地址空间\n",
    "\n",
    "每一个输入分量均扩充到c维\n",
    "\n",
    "对于一个特定的输入分量$s_n$，有对应的扩充后向量$\\bm{m_n}$\n",
    "\n",
    "扩充后向量按照如下的方式进行运算\n",
    "\n",
    "定义如下的取余运算\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\Psi(s_n) = mod(\\frac{s_n-1}{c})+1\n",
    "\\end{equation}\n",
    "$$\n",
    "则$\\bm{m_n}$的第$\\Psi(s_n)$位为$s_n$，其他位依次推出\n",
    "\n",
    "|$\\bm{m_{n1}}$|$\\bm{m_{n2}}$|$\\cdots$|$\\bm{m_{n\\Psi(s_n)}}$|$\\cdots$|$\\bm{m_{nc}}$|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|$s_n+(c-\\Psi(s_n)+1)$|$s_n+(c-\\Psi(s_n)+2)$|$\\cdots$|$s_n$|$\\cdots$|$s_n+(c-\\Psi(s_n))$|\n",
    "\n",
    "### 扩充地址空间到虚拟存储空间\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c138c3a39b15f82bd4a9598693589d2dc2de979d592ed7357973539f0f36bd2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('flyai_pytorch1_5': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
