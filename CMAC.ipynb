{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebellar Model Articulation Controller(CMAC)\n",
    "\n",
    "\n",
    "## 概论\n",
    "小脑模型的初始设想很简单，希望设计一个这样的模型：\n",
    "\n",
    "1. **足够快**\n",
    "2. **拟合**\n",
    "\n",
    "### 足够快\n",
    "对于第一点，传统的神经网络均是使用浮点数进行计算，使用浮点数显然存在两个缺点：其一是占用空间大，其二是运算不够快。但也存在非常明显的优点：计算精度高。\n",
    "\n",
    "若为了在不太降低精度的条件下尽可能提高模型运算效率，显然有两个角度：其一是改进模型，其二是改变数值存储方式。\n",
    "\n",
    "量化技术就是这样一类通过改变数值存储方式提高模型运算效率的方式。对于现代神经网络，训练通常采用32位浮点数，推理时则可以选用16位浮点数以提高精度，而当部署到边缘设备上时则可以进一步采用**int8量化技术**。\n",
    "\n",
    "对于CMAC，同样的，为了提升运算效率，初始数据输入时会进行量化。此外，为了进一步提升效率，CMAC还引入了**哈希散列**，通过查表的方式将相近的输入映射到相似的地址上。\n",
    "\n",
    "哈希散列同时也引入了不确定的因素。哈希散列是一种压缩映射，其很有可能将不同的输入映射到同一个地址，即导致了**碰撞**。从另一个角度讲，这也引入了非线性变换，即在原空间可能相隔非常远的两个输入，在映射后可能十分相近甚至发生**碰撞**。\n",
    "\n",
    "\n",
    "### 拟合\n",
    "为了实现拟合，CMAC在查表后建立了一个自适应线性层，实现地址到输出的线性估计\n",
    "由于采用了哈希，实际上建立了输入与地址的映射表。在不考虑碰撞的情况下，一个特定的输入会激活特定的地址，而特定的地址会激活特定的自适应线性层的输入单元，这些单元则会连接到输出。\n",
    "\n",
    "不同于传统的神经网络，进行推理时同层所有的神经元均会参与运算，CMAC中仅有被激活的输入单元才会参与运算，这显然也加速了CMAC的运算速度。\n",
    "\n",
    "\n",
    "## 符号定义\n",
    "\n",
    "### 空间\n",
    "|符号|含义|\n",
    "|:-:|:-:|\n",
    "|$S$|输入空间|\n",
    "|$M$|扩充地址空间|\n",
    "|$MC$|扩充地址空间长度|\n",
    "|$A_c$|虚拟存储空间|\n",
    "|$A_p$|实际存储空间|\n",
    "|$F$|输出空间|\n",
    "\n",
    "### 数据\n",
    "|符号|含义|\n",
    "|:-:|:-:|\n",
    "|$\\bm{s}$|输入向量|\n",
    "|$\\bm{m}$|扩充后矩阵|\n",
    "|$\\bm{a}$|虚拟存储空间向量|\n",
    "|$\\bm{d}$|实际存储空间向量|\n",
    "|$\\hat{y}$|预测输出|\n",
    "|$y$|真实输出|\n",
    "\n",
    "### 参数\n",
    "|符号|含义|\n",
    "|:-:|:-:|\n",
    "|s|输入空间维度|\n",
    "|q|量化级|\n",
    "|c|扩充地址维度|\n",
    "|$N_p$|用于Hash运算的质数|\n",
    "|$\\bm{W}$|权矩阵|\n",
    "\n",
    "## 正向运算\n",
    "\n",
    "CMAC的整体流程如下：\n",
    "\n",
    "* 输入空间$S$离散化\n",
    "* 输入空间$S$ $\\rightarrow$ 扩充地址空间$M$\n",
    "* 扩充地址空间$M$ $\\rightarrow$ 虚拟存储空间$A_c$\n",
    "* 虚拟存储空间$A_c$ $\\rightarrow$ 实际存储空间$A_p$\n",
    "* 实际存储空间$A_p$ $\\rightarrow$ 输出空间$F$\n",
    "\n",
    "第零步为离散化。一方面是加速运算，另一方面也是配合后续的Hash\n",
    "\n",
    "第一步是在进行升维\n",
    "\n",
    "第二步是将第一步中升维到高维的多个分量组合为一个向量\n",
    "\n",
    "第三步为Hash\n",
    "\n",
    "第四步为自适应线性拟合\n",
    "\n",
    "### 离散化\n",
    "\n",
    "输入为$\\bm{s}=[s_1, s_2, \\cdots, s_s]$\n",
    "\n",
    "设定第n个维度的取值范围为$[n_{min}, n_{max}]$，量化级为q_n\n",
    "\n",
    "则第n个维度的离散值为\n",
    "$$\n",
    "\\begin{equation}\n",
    "    s_n = \\lceil\\frac{(s_n-n_{min})}{(n_{max}-n_{min})}*q_n\\rceil\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### 输入空间到扩充地址空间\n",
    "\n",
    "每一个输入分量均扩充到c维\n",
    "\n",
    "对于一个特定的输入分量$s_n$，有对应的扩充后向量$\\bm{m_n}$\n",
    "\n",
    "扩充后向量按照如下的方式进行运算\n",
    "\n",
    "定义如下的取余运算\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\Psi(s_n) = mod(\\frac{s_n-1}{c})+1\n",
    "\\end{equation}\n",
    "$$\n",
    "则$\\bm{m_n}$的第$\\Psi(s_n)$位为$s_n$，其他位依次推出\n",
    "\n",
    "|$\\bm{m_{n1}}$|$\\bm{m_{n2}}$|$\\cdots$|$\\bm{m_{n\\Psi(s_n)}}$|$\\cdots$|$\\bm{m_{nc}}$|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|$s_n+(c-\\Psi(s_n)+1)$|$s_n+(c-\\Psi(s_n)+2)$|$\\cdots$|$s_n$|$\\cdots$|$s_n+(c-\\Psi(s_n))$|\n",
    "\n",
    "### 扩充地址空间到虚拟存储空间\n",
    "\n",
    "扩充地址空间为一个$s\\times c$的矩阵，转换到虚拟存储空间后进行纵向连接，即进行如下操作\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\bm{m} = \n",
    "    \\left[\\begin{array}{cc}\n",
    "        m_{11}&m_{12}&\\cdots&m_{1c} \\\\\n",
    "        \\vdots&\\ddots&\\ddots&\\vdots \\\\\n",
    "        m_{s1}&m_{s2}&\\cdots&m_{sc}\n",
    "    \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\bm{a} \n",
    "        &= [a_1, a_2, \\cdots, a_c]^T \\\\\n",
    "        &= [m_{11}m_{21}\\cdots m_{s1}, m_{12}m_{22}\\cdots m_{s2}, \\cdots, m_{1c}m_{2c}\\cdots m_{sc}]^T \n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### 虚拟存储空间到实际存储空间\n",
    "\n",
    "这一步即为Hash，在这里采用取余运算的方式，类似于式2有：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\Psi(a_n) = mod(\\frac{a_n-1}{N_p})+1\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\bm{d} \n",
    "        &= [d_1, d_2, \\cdots, d_c]^T \\\\\n",
    "        &= [\\Psi(a_1), \\Psi(a_2), \\cdots, \\Psi(a_c)]^T\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "### 实际存储空间到输出空间\n",
    "\n",
    "这一步采用简单的线性变换\n",
    "\n",
    "上述得到的是地址，在CMAC中，为了加速运算，最终一步是通过查询实现的，\n",
    "\n",
    "权矩阵$\\bm{W}\\in\\mathcal{R}^{c \\times N_p}$\n",
    "\n",
    "其中$c$为地址的维度，$N_p$为取余运算的除数，对于以$N_p$为底的除法，显然得到的余数不可能大于$N_p$\n",
    "\n",
    "输出即为对应地址位置的权值之和\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\hat{y} = \\sum_{i=0}^{c}W[i, \\Psi(a_i)]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "## 参数学习\n",
    "\n",
    "定义损失函数\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathcal{L} = ||\\hat{y}-y||_2^2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "对权值求偏导\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "    \\frac{\\partial \\mathcal{L}}{\\partial \\bm{W}} \n",
    "    &= \\frac{||\\hat{y}-y||_2^2}{\\partial \\bm{W}} \\\\\n",
    "    &= \\frac{(\\sum_{i=0}^{c}W[i, \\Psi(a_i)]-y)^2}{\\partial \\bm{W}} \\\\\n",
    "    &= 2(\\sum_{i=0}^{c}W[i, \\Psi(a_i)]-y)\\frac{\\sum_{i=0}^{c}W[i, \\Psi(a_i)]}{\\partial \\bm{W}}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal{L}}{W_{ij}} = \n",
    "    \\left\\{\n",
    "    \\begin{array}{cc}\n",
    "    0,&d_i \\neq j+1 \\\\\n",
    "    2(\\sum_{i=0}^{c}W[i, \\Psi(a_i)]-y),&else\n",
    "    \\end{array}\n",
    "    \\right. \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "获得参数更新函数\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\bm{W}(t+1) = \\bm{W}(t) - \\eta\\frac{\\partial \\mathcal{L}}{\\bm{W}(t)}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMAC(object):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 input_range,  \n",
    "                 q_level, \n",
    "                 expend_dim, \n",
    "                 hash_number,\n",
    "                 lr):\n",
    "        \"\"\"\n",
    "        input_dim: 输入维度\n",
    "        input_range: 输入取值范围，默认需要一个list\n",
    "        q_level: 量化级，默认需要输入一个list\n",
    "        expend_dim: 扩充地址维度\n",
    "        hash_number: 用于散列的质数\n",
    "        lr: 学习率\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.input_range = np.array(input_range)\n",
    "        self.q_level = q_level\n",
    "        self.expend_dim = expend_dim\n",
    "        self.hash_number = hash_number\n",
    "        self.lr = lr\n",
    "\n",
    "        # 输出权值矩阵\n",
    "        random.seed(1024)\n",
    "        np.random.seed(1024)\n",
    "        self.weight_matrix = np.random.rand(self.expend_dim, self.hash_number)\n",
    "\n",
    "        # 数据存储空间向量\n",
    "        self.real_vector = None\n",
    "        self.output_vector = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: 输入向量\n",
    "        \"\"\"\n",
    "\n",
    "        # ------------- 离散化 ---------------\n",
    "        input_q = self._quantification(np.array(x))\n",
    "        \n",
    "        # ------------- 输入空间到扩充地址空间 ------------------\n",
    "        # (self.expend_dim, self.input_dim)\n",
    "        expend_matrix = self._input2expend(input_q)\n",
    "\n",
    "        # ------------- 扩充地址空间到虚拟存储空间 -----------------\n",
    "        # (self.expend_dim, 1)\n",
    "        virtual_vector = self._expend2virtual(expend_matrix)\n",
    "\n",
    "        # ------------- 虚拟存储空间到实际存储空间 ------------------\n",
    "        # (self.expend_dim, 1)\n",
    "        self.real_vector = self._virtual2real(virtual_vector)\n",
    "\n",
    "        # ------------- 实际存储空间到输出空间 --------------------\n",
    "        # (self.output_dim, 1)\n",
    "        self.output_value = self._real2output(self.real_vector)\n",
    "\n",
    "        return self.output_value\n",
    "    \n",
    "    def optim(self, true_output):\n",
    "        \"\"\"\n",
    "        true_output: 真实输出\n",
    "        \"\"\"\n",
    "\n",
    "        # 更新mask\n",
    "        partial_matrix = np.zeros((self.expend_dim, self.hash_number))\n",
    "        partial_matrix[range(0, self.expend_dim), self.real_vector.reshape(-1)-1] = 1\n",
    "        self.weight_matrix -= self.lr * (self.output_value - true_output) * partial_matrix\n",
    "\n",
    "    def _quantification(self, input_vector):\n",
    "        \"\"\"\n",
    "        input_vector: 输入向量\n",
    "        \"\"\"\n",
    "        if isinstance(self.q_level, int):\n",
    "            self.q_level = np.ones((self.input_dim)) * self.q_level\n",
    "\n",
    "        input_q = np.zeros(self.input_dim, dtype=np.int32)\n",
    "        # (self.input_dim)\n",
    "        for i in range(self.input_dim):\n",
    "            _input_range = self.input_range[i, :]\n",
    "            input_q[i] = np.math.ceil((input_vector[i]-_input_range[0])*self.q_level[i]/(_input_range[1]-_input_range[0]))\n",
    "\n",
    "        return input_q\n",
    "\n",
    "    def _input2expend(self, input_q):\n",
    "        \"\"\"\n",
    "        input_q: 量化后的输入向量\n",
    "        \"\"\"\n",
    "        expend_matrix = np.zeros((self.input_dim, self.expend_dim))\n",
    "\n",
    "        for i in range(self.input_dim):\n",
    "            \n",
    "            # 计算取余运算\n",
    "            phi_ = self.my_mod(input_q[i], self.expend_dim)\n",
    "            \n",
    "            if phi_ != 0:\n",
    "                # index < phi_\n",
    "                add_number_list_1 = np.array(range(0, phi_))+1\n",
    "                # index > phi_\n",
    "                add_number_list_2 = np.array(range(0, self.expend_dim-phi_))\n",
    "\n",
    "                expend_matrix[i, :phi_] = input_q[i] + self.expend_dim - phi_ + add_number_list_1\n",
    "                expend_matrix[i, phi_:] = input_q[i] + add_number_list_2\n",
    "            else:\n",
    "                expend_matrix[i] = input_q[i] + np.array(range(0, self.expend_dim))\n",
    "\n",
    "        return expend_matrix.astype(np.int32).T\n",
    "    \n",
    "    @staticmethod\n",
    "    def my_mod(input_, divisor):\n",
    "        return (input_-1)%divisor + 1\n",
    "\n",
    "    def _expend2virtual(self, expend_matrix):\n",
    "        \"\"\"\n",
    "        expend_matrix: 扩充地址空间矩阵\n",
    "        \"\"\"\n",
    "        virtual_vector = np.zeros((self.expend_dim, 1), dtype=np.int32)\n",
    "\n",
    "        # 进行组合\n",
    "        for i in range(self.input_dim):\n",
    "            mul_num = pow(10, self.input_dim-1-i)\n",
    "            virtual_vector += expend_matrix[:, i:i+1] * mul_num\n",
    "    \n",
    "        return virtual_vector\n",
    "    \n",
    "    def _virtual2real(self, virtual_vector):\n",
    "        \"\"\"\n",
    "        virtual_vector: 虚拟存储空间向量\n",
    "        \"\"\"\n",
    "        real_vector = np.zeros((self.expend_dim, 1), dtype=np.int32)\n",
    "        for i in range(self.expend_dim):\n",
    "            real_vector[i] = self.my_mod(virtual_vector[i], self.hash_number)\n",
    "\n",
    "        return real_vector\n",
    "\n",
    "    def _real2output(self, real_vector):\n",
    "        \"\"\"\n",
    "        real_vector: 实际存储空间向量\n",
    "        \"\"\"\n",
    "        output_value = np.sum(self.weight_matrix[range(0, self.expend_dim), real_vector.reshape(-1)-1])\n",
    "\n",
    "        return output_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离散\n",
      " [4 0]\n",
      "扩充地址空间\n",
      " [[5 1]\n",
      " [6 2]\n",
      " [7 3]\n",
      " [8 4]]\n",
      "虚拟存储空间\n",
      " [[51]\n",
      " [62]\n",
      " [73]\n",
      " [84]]\n",
      "实际存储空间\n",
      " [[13]\n",
      " [ 5]\n",
      " [16]\n",
      " [ 8]]\n",
      "输出\t 2.3467477938946764\n",
      "参数学习\n",
      "step:0\t output_value:2.346748\n",
      "step:1\t output_value:1.808049\n",
      "step:2\t output_value:1.484829\n",
      "step:3\t output_value:1.290898\n",
      "step:4\t output_value:1.174539\n",
      "step:5\t output_value:1.104723\n",
      "step:6\t output_value:1.062834\n",
      "step:7\t output_value:1.037700\n",
      "step:8\t output_value:1.022620\n",
      "step:9\t output_value:1.013572\n",
      "step:10\t output_value:1.008143\n",
      "step:11\t output_value:1.004886\n",
      "step:12\t output_value:1.002932\n",
      "step:13\t output_value:1.001759\n",
      "step:14\t output_value:1.001055\n",
      "step:15\t output_value:1.000633\n",
      "step:16\t output_value:1.000380\n",
      "step:17\t output_value:1.000228\n",
      "step:18\t output_value:1.000137\n",
      "step:19\t output_value:1.000082\n"
     ]
    }
   ],
   "source": [
    "# 测试数据\n",
    "\n",
    "# 输入维度\n",
    "input_dim = 2\n",
    "# 输入范围\n",
    "input_range = [[0, 1], [0, 0.8]]\n",
    "# 量化级\n",
    "q_levle = [5, 4]\n",
    "# 扩充地址空间维度\n",
    "expend_dim = 4\n",
    "# 散列质数\n",
    "hash_number = 19\n",
    "# 学习率\n",
    "lr = 0.1\n",
    "# 输出维度\n",
    "output_dim = 1\n",
    "\n",
    "# 测试输入\n",
    "input_vector = [0.8, 0]\n",
    "# 测试输出\n",
    "output_ = 1\n",
    "\n",
    "my_cmac = CMAC(input_dim=input_dim,\n",
    "               input_range=input_range,\n",
    "               q_level=q_levle,\n",
    "               expend_dim=expend_dim,\n",
    "               hash_number=hash_number,\n",
    "               lr=lr)\n",
    "\n",
    "# 离散值输出\n",
    "input_q = my_cmac._quantification(input_vector)\n",
    "print(\"离散\\n\", input_q)\n",
    "# 输入空间到扩充地址空间\n",
    "expend_matrix = my_cmac._input2expend(input_q)\n",
    "print(\"扩充地址空间\\n\", expend_matrix)\n",
    "# 扩充地址空间到虚拟存储空间\n",
    "virtual_vector = my_cmac._expend2virtual(expend_matrix)\n",
    "print(\"虚拟存储空间\\n\", virtual_vector)\n",
    "# 虚拟存储空间到实际存储空间\n",
    "real_vector = my_cmac._virtual2real(virtual_vector)\n",
    "print(\"实际存储空间\\n\", real_vector)\n",
    "# 实际存储空间到输出空间\n",
    "output_value = my_cmac._real2output(real_vector)\n",
    "print(\"输出\\t\", output_value)\n",
    "\n",
    "# 参数优化\n",
    "print(\"参数学习\")\n",
    "for step in range(20):\n",
    "    output_value_2 = my_cmac.forward(input_vector)\n",
    "    my_cmac.optim(output_)\n",
    "    print(\"step:{}\\t output_value:{:.6f}\".format(step, output_value_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c138c3a39b15f82bd4a9598693589d2dc2de979d592ed7357973539f0f36bd2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('flyai_pytorch1_5': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
