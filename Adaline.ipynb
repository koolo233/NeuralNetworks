{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自适应线性神经元（Adaline）\n",
    "\n",
    "## 定义\n",
    "自适应神经元是在感知机的基础上的一种改进。其激活函数不再是阶跃函数，而是线性连续函数\n",
    "\n",
    "## 对比\n",
    "|项目|自适应神经元|感知机|\n",
    "|--|--|--|\n",
    "|激活函数|线性激活函数|阶跃函数（Sign等）|\n",
    "|损失函数|均方误差（MSE）|无|\n",
    "|参数更新方式|梯度下降法|人为定义|\n",
    "|应用|分类、回归|分类|\n",
    "\n",
    "## 模型定义\n",
    "\n",
    "* 输入：向量$x_i=[x_{i1}, x_{i2}, \\cdots, x_{in}]^T, \\ x \\in \\mathcal{R}^n$\n",
    "* 权重：向量$\\omega = [\\omega_1, \\omega_2, \\cdots, \\omega_n]^T, \\ \\omega \\in \\mathcal{R}^n$\n",
    "* 偏置：$b, \\ b\\in \\mathcal{R}$\n",
    "* 输出：$o_i, \\ o_i\\in \\mathcal{R}$\n",
    "* 样本实际输出： $y_i, \\ y_i \\in mathcal{R}$\n",
    "* 运算：$$o_i = purelin(\\omega^Tx_i+b)$$\n",
    "\n",
    "## 学习算法\n",
    "\n",
    "### 一次性学习算法\n",
    "$$\\left\\{ \\begin{array}{rcl} \\omega_1 \\cdot x_{11} + \\omega_2 \\cdot x_{12} + \\cdots + \\omega_n \\cdot x_{1n} + b = y_1 \\\\ \\omega_1 \\cdot x_{21} + \\omega_2 \\cdot x_{22} + \\cdots + \\omega_n \\cdot x_{2n} + b = y_2 \\\\ \\vdots \\\\ \\omega_1 \\cdot x_{m1} + \\omega_2 \\cdot x_{m2} + \\cdots + \\omega_n \\cdot x_{mn} + b = y_m \\\\\\end{array}\\right.$$\n",
    "\n",
    "可以得到\n",
    "\n",
    "$$\\left[ \\begin{array}{cc} x_{11} & \\cdots& x_{1n}& 1 \\\\ \\vdots& \\ddots& \\vdots& \\vdots \\\\ x_{m1}& \\cdots& x_{mn} &1  \\end{array}\\right]  \\left[ \\begin{array}{cc} \\omega_1 \\\\ \\vdots \\\\ \\omega_n \\\\ b \\end{array}\\right] = \\left[ \\begin{array}{cc} y_1 \\\\ \\vdots \\\\ y_m \\end{array} \\right] $$\n",
    "\n",
    "因此可以解得参数向量$$\\textbf{W} = (X^TX)^{-1}X^TY$$\n",
    "\n",
    "由于实际情况中，数据存在一定的噪声，上述的计算方法不一定有解。\n",
    "\n",
    "### 迭代解法\n",
    "\n",
    "Adaline的输出为：\n",
    "$$o_i = \\omega^Tx_i+b = W^TX_i \\\\ W^T = [\\omega_1, \\cdots, \\omega_n, b]^T\\\\ X_i = [x_{i1}, \\cdots, x_{in}, 1]$$\n",
    "\n",
    "由此可得输出与真实值之间的绝对误差为\n",
    "$$e(o_i) = y_i - o_i$$\n",
    "绝对误差限位\n",
    "$$e(o_i)_\\epsilon = |y_i - o_i|$$\n",
    "由二范数定义的输出与真实值之差的距离度量为\n",
    "$$d(o_i-y_i)_2 = ||o_i-y_i||_2 = (o_i - y_i)^2$$\n",
    "\n",
    "上述定义了输出和真实值之间的距离，因此优化目标即为减小这一差距\n",
    "\n",
    "* **定义Adaline的损失函数**\n",
    "\n",
    "在单个样本上的损失函数为$$L(\\textbf{W})_i = (o_i - y_i)^2$$\n",
    "在整个样本集上的损失函数为$$L(\\textbf{W}) = \\sum_{i=0}^m(o_i - y_i)^2$$\n",
    "\n",
    "* **定义Adaline待解决的优化问题**\n",
    "$$\\min\\limits_{\\textbf{W}}L(\\textbf{W}) = \\sum_{i=0}^m(o_i - y_i)^2$$\n",
    "\n",
    "**优化问题求解**\n",
    "\n",
    "计算损失关于未知参数的偏导\n",
    "\n",
    "$$\\begin{split} \\bigtriangledown_\\textbf{W}L(\\textbf{W}) &= \\frac{\\partial L(\\textbf{W})}{\\partial \\textbf{W}} \\\\  &=\\frac{\\partial(\\sum_{i=0}^m(o_i - y_i)^2)}{\\partial(\\textbf{W})} \\\\  &= \\frac{\\partial(\\sum_{i=0}^m(W^TX_i - y_i)^2)}{\\partial(\\textbf{W})} \\\\ &=2\\sum_{i=0}^m(W^TX_i - y_i)X_i \\end{split} $$\n",
    "\n",
    "得到未知参数的更新方程，对于第n+1次更新有\n",
    "$$\\textbf{W}(n+1) = \\textbf{W}(n) - \\eta \\bigtriangledown_\\textbf{W}(n)L(\\textbf{W}(n))$$\n",
    "\n",
    "其中 $\\eta$为学习率\n",
    "\n",
    "由上式即可得到全量梯度下降法(BGD)\n",
    "\n",
    "* **全量梯度下降法(BGD)**\n",
    "$$\\begin{split} \\textbf{W}(n+1) &= \\textbf{W}(n) - \\eta \\bigtriangledown_\\textbf{W}(n)L(\\textbf{W}(n))\\\\ &=  \\textbf{W}(n) - 2\\eta\\sum_{i=0}^m(W(n)^TX_i - y_i)X_i \\end{split}$$\n",
    "* **随机梯度下降法(SGD)**\n",
    "\n",
    "定义第n+1次更新时取得的样本为\n",
    "$$\\{X(n+1), y(n+1)\\}$$\n",
    "\n",
    "可得\n",
    "$$\\begin{split} \\textbf{W}(n+1) &= \\textbf{W}(n) - \\eta \\bigtriangledown_\\textbf{W}(n)L(\\textbf{W}(n))\\\\ &=  \\textbf{W}(n) - 2\\eta(W(n)^TX(n+1) - y(n+1))X(n+1) \\end{split}$$\n",
    "* **小批量梯度下降法(MBGD)**\n",
    "\n",
    "定义第n+1次更新时取得的样本集$S$一共有$s$个样本，\n",
    "$$S(n+1) = \\{(X_1(n+1), y_1(n+1)), (X_2(n+1), y_2(n+1)), \\cdots, (X_s(n+1), y_s(n+1))\\}, \\ S(n+1) \\subsetneq T$$\n",
    "\n",
    "可得\n",
    "$$\\begin{split} \\textbf{W}(n+1) &= \\textbf{W}(n) - \\eta \\bigtriangledown_\\textbf{W}(n)L(\\textbf{W}(n))\\\\ &=  \\textbf{W}(n) - 2\\eta\\sum_{i=0}^s(W(n)^TX_i(n+1) - y_i(n+1))X_i(n+1) \\end{split}$$\n",
    "\n",
    "\n",
    "### 训练流程\n",
    "\n",
    "\n",
    "### 应用\n",
    "\n",
    "* 线性系统辨识\n",
    "* 滤波\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
